{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0 Run 0 Results *****\n",
      "Validation gini: 0.27483\n",
      "\n",
      "\n",
      "Fold 0 Run 1 Results *****\n",
      "Validation gini: 0.27151\n",
      "\n",
      "\n",
      "Fold 0 Run 2 Results *****\n",
      "Validation gini: 0.27793\n",
      "\n",
      "\n",
      "Fold 0 prediction cv gini: 0.27793\n",
      "\n",
      "\n",
      "Fold 1 Run 0 Results *****\n",
      "Validation gini: 0.28427\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(20)\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "'''Data loading & preprocessing\n",
    "'''\n",
    "\n",
    "X_train = pd.read_csv(\"Data/train.csv.gz\")\n",
    "X_test = pd.read_csv(\"Data/test.csv.gz\")\n",
    "\n",
    "X_train, y_train = X_train.iloc[:,2:], X_train.target\n",
    "X_test, test_id = X_test.iloc[:,1:], X_test.id\n",
    "\n",
    "#OHE / some feature engineering adapted from the1owl kernel at:\n",
    "#https://www.kaggle.com/the1owl/forza-baseline/code\n",
    "\n",
    "#excluded columns based on snowdog's old school nn kernel at:\n",
    "#https://www.kaggle.com/snowdog/old-school-nnet\n",
    "\n",
    "X_train['negative_one_vals'] = np.sum((X_train==-1).values, axis=1)\n",
    "X_test['negative_one_vals'] = np.sum((X_test==-1).values, axis=1)\n",
    "\n",
    "to_drop = ['ps_car_11_cat', 'ps_ind_14', 'ps_car_11', 'ps_car_14', 'ps_ind_06_bin', \n",
    "           'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin', 'ps_ind_12_bin', \n",
    "           'ps_ind_13_bin']\n",
    "\n",
    "cols_use = [c for c in X_train.columns if (not c.startswith('ps_calc_'))\n",
    "             & (not c in to_drop)]\n",
    "             \n",
    "X_train = X_train[cols_use]\n",
    "X_test = X_test[cols_use]\n",
    "\n",
    "one_hot = {c: list(X_train[c].unique()) for c in X_train.columns}\n",
    "\n",
    "#note that this encodes the negative_one_vals column as well\n",
    "for c in one_hot:\n",
    "    if len(one_hot[c])>2 and len(one_hot[c]) < 105:\n",
    "        for val in one_hot[c]:\n",
    "            newcol = c + '_oh_' + str(val)\n",
    "            X_train[newcol] = (X_train[c].values == val).astype(np.int)\n",
    "            X_test[newcol] = (X_test[c].values == val).astype(np.int)\n",
    "        X_train.drop(labels=[c], axis=1, inplace=True)\n",
    "        X_test.drop(labels=[c], axis=1, inplace=True)\n",
    "            \n",
    "X_train = X_train.replace(-1, np.NaN)  # Get rid of -1 while computing interaction col\n",
    "X_test = X_test.replace(-1, np.NaN)\n",
    "\n",
    "X_train['ps_car_13_x_ps_reg_03'] = X_train['ps_car_13'] * X_train['ps_reg_03']\n",
    "X_test['ps_car_13_x_ps_reg_03'] = X_test['ps_car_13'] * X_test['ps_reg_03']\n",
    "\n",
    "X_train = X_train.fillna(-1)\n",
    "X_test = X_test.fillna(-1)\n",
    "\n",
    "'''Gini scoring function\n",
    "'''\n",
    "\n",
    "#gini scoring function from kernel at: \n",
    "#https://www.kaggle.com/tezdhar/faster-gini-calculation\n",
    "def ginic(actual, pred):\n",
    "    n = len(actual)\n",
    "    a_s = actual[np.argsort(pred)]\n",
    "    a_c = a_s.cumsum()\n",
    "    giniSum = a_c.sum() / a_c[-1] - (n + 1) / 2.0\n",
    "    return giniSum / n\n",
    " \n",
    "def gini_normalizedc(a, p):\n",
    "    return ginic(a, p) / ginic(a, a)\n",
    "\n",
    "'''5-fold neural network training \n",
    "'''\n",
    "\n",
    "K = 5 #number of folds\n",
    "runs_per_fold = 3 #bagging on each fold\n",
    "\n",
    "cv_ginis = []\n",
    "y_preds = np.zeros((np.shape(X_test)[0],K))\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = K, \n",
    "                            random_state = 100, \n",
    "                            shuffle = True)    \n",
    "\n",
    "for i, (f_ind, outf_ind) in enumerate(kfold.split(X_train, y_train)):\n",
    "\n",
    "    X_train_f, X_val_f = X_train.loc[f_ind].copy(), X_train.loc[outf_ind].copy()\n",
    "    y_train_f, y_val_f = y_train[f_ind], y_train[outf_ind]\n",
    "          \n",
    "    #upsampling adapted from kernel: \n",
    "    #https://www.kaggle.com/ogrellier/xgb-classifier-upsampling-lb-0-283\n",
    "    pos = (pd.Series(y_train_f == 1))\n",
    "    \n",
    "    # Add positive examples\n",
    "    X_train_f = pd.concat([X_train_f, X_train_f.loc[pos]], axis=0)\n",
    "    y_train_f = pd.concat([y_train_f, y_train_f.loc[pos]], axis=0)\n",
    "    \n",
    "    # Shuffle data\n",
    "    idx = np.arange(len(X_train_f))\n",
    "    np.random.shuffle(idx)\n",
    "    X_train_f = X_train_f.iloc[idx]\n",
    "    y_train_f = y_train_f.iloc[idx]\n",
    "    \n",
    "    #track oof bagged prediction for cv scores\n",
    "    val_preds = 0\n",
    "    \n",
    "    for j in range(runs_per_fold):\n",
    "        NN=Sequential()\n",
    "        NN.add(Dense(35,activation='relu',input_dim=np.shape(X_train_f)[1]))\n",
    "        NN.add(Dropout(0.3))\n",
    "        NN.add(Dense(1,activation='sigmoid'))\n",
    "        \n",
    "        NN.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        \n",
    "        set_random_seed(1000*i+j)\n",
    "            \n",
    "        NN.fit(X_train_f.values, y_train_f.values, epochs=15, batch_size=2048, verbose=0)\n",
    "         \n",
    "        val_gini = gini_normalizedc(y_val_f.values, NN.predict(X_val_f.values)[:,0])   \n",
    "        print ('\\nFold %d Run %d Results *****' % (i, j))\n",
    "        print ('Validation gini: %.5f\\n' % (val_gini))\n",
    "        \n",
    "        val_preds += NN.predict(X_val_f.values)[:,0] / runs_per_fold\n",
    "        y_preds[:,i] += NN.predict(X_test.values)[:,0] / runs_per_fold\n",
    "        \n",
    "    cv_ginis.append(val_gini)\n",
    "    print ('\\nFold %i prediction cv gini: %.5f\\n' %(i,val_gini))\n",
    "    \n",
    "print('Mean out of fold gini: %.5f' % np.mean(cv_ginis))\n",
    "y_pred_final = np.mean(y_preds, axis=1)\n",
    "\n",
    "df_sub = pd.DataFrame({'id' : test_id, \n",
    "                       'target' : y_pred_final},\n",
    "                       columns = ['id','target'])\n",
    "df_sub.to_csv('NNShallow_5fold_3runs_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
