{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding=utf-8\n",
    "from sklearn.metrics import roc_auc_score, recall_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, OneHotEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "def load_data():\n",
    "    df = pd.read_csv(\"Data/train.csv.gz\")\n",
    "    return df\n",
    "\n",
    "def eval_matric(y_true, y_prob):\n",
    "    print(\"true p ratio\", sum(y_true)/ len(y_true))\n",
    "    y_pred = [1 if i> 0.5 else 0 for i in y_prob]\n",
    "    print(\"recall ratio\", sum(y_pred)/float(sum(y_true)))\n",
    "\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i * delta\n",
    "        delta += 1 - y_i\n",
    "        gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n",
    "    print(\"gini:\", gini)\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input,Dense, concatenate,Dropout,BatchNormalization,Activation,Flatten,Add, Conv2D, Dot, dot\n",
    "from keras.layers import RepeatVector, merge, Subtract, Lambda, Multiply, Embedding, Concatenate, Reshape, DepthwiseConv2D\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model\n",
    "from keras.engine.topology import Layer\n",
    "from sklearn.metrics import roc_auc_score, recall_score\n",
    "    \n",
    "def CIN(x, conv_layer):\n",
    "    cat_output_expand = Lambda(lambda x: K.expand_dims(x, axis = 2))(x)\n",
    "\n",
    "    # shape: -1, 1, feature_size, dim\n",
    "    x_0 = Lambda(lambda x: K.permute_dimensions(x, (0,3,2,1)))(cat_output_expand)\n",
    "    x_next = cat_output_expand\n",
    "\n",
    "    cin_output = []\n",
    "    for layer in conv_layer:\n",
    "        x = Lambda(lambda x: K.permute_dimensions(x, (0,3,1,2)))(x_next)\n",
    "        z_0 = Lambda(lambda x: K.batch_dot(x[0], x[1], axes=(2,3)))([x_0, x])\n",
    "        z_1 = Lambda(lambda x: K.permute_dimensions(x, (0,2,3,1)))(z_0)\n",
    "\n",
    "        x_next_list = []\n",
    "        pooling_output_list = []\n",
    "        for index in range(layer):\n",
    "            #depth_multiplier=3\n",
    "            output = DepthwiseConv2D((int(z_1.shape[1]), int(z_1.shape[2])))(z_1)\n",
    "            #output = Conv2D(3, (int(z_1.shape[1]), int(z_1.shape[2])) )(z_1)\n",
    "            output = Lambda(lambda x: K.squeeze(x, 2))(output)\n",
    "            pooling_output = Lambda(lambda x: K.sum(output, axis = 2))(output)\n",
    "            pooling_output_list.append(pooling_output)\n",
    "            x_next_list.append(output)\n",
    "        x_next = Concatenate(axis = 1)(x_next_list)\n",
    "        x_next = Lambda(lambda x: K.expand_dims(x, axis = 2))(x_next)\n",
    "\n",
    "        x_pooling = Concatenate(axis = 1)(pooling_output_list)\n",
    "        cin_output.append(x_pooling)\n",
    "\n",
    "    cin_output =  Concatenate(axis = 1)(cin_output)\n",
    "    cin_output = Dense(1, activation='linear')(cin_output)\n",
    "    return cin_output\n",
    "    \n",
    "class XDeepFM():\n",
    "    def __init__(self, sparse_features, dense_features, sparse_label_dict, hidden_layer, cov_layer, embed_dim):\n",
    "        self.sparse_features = sparse_features\n",
    "        self.dense_features = dense_features\n",
    "        self.sparse_label_dict = sparse_label_dict\n",
    "        self.hidden_layer = hidden_layer\n",
    "        self.embed_dim = embed_dim\n",
    "        self.sparse_label_dict = sparse_label_dict\n",
    "        self.con_layer = cov_layer\n",
    "        \n",
    "    def fit(self, train, y_train, n_epoch=100, n_batch = 1000):\n",
    "        cat_input = []\n",
    "        cat_output = []\n",
    "        for col in self.sparse_features:\n",
    "            input = Input(shape= (1,))\n",
    "            cat_input.append(input)\n",
    "            emb = Embedding(self.sparse_label_dict[col], self.embed_dim, input_length =1 ,trainable = True)(input)\n",
    "            cat_output.append(emb)\n",
    "         \n",
    "        cat_output = Concatenate(axis=1)(cat_output)\n",
    "        \n",
    "        #first_order = Added_Weights(use_bias = True)(cat_output)\n",
    "        first_order = Flatten()(cat_output)\n",
    "        first_order = Dense(1, activation='linear')(first_order)\n",
    "        \n",
    "        # 需要使用lambda 层封装Backend 的函数操作\n",
    "        #first_order = Lambda(lambda x: K.sum(x, axis =1, keepdims=True))(first_order)\n",
    "        cin_output = CIN(cat_output, self.con_layer)\n",
    "        '''\n",
    "        cat_output_expand = Lambda(lambda x: K.expand_dims(x, axis = 2))(cat_output)\n",
    "\n",
    "        # shape: -1, 1, feature_size, dim\n",
    "        x_0 = Lambda(lambda x: K.permute_dimensions(x, (0,3,2,1)))(cat_output_expand)\n",
    "        x_next = cat_output_expand\n",
    "    \n",
    "        cin_output = []\n",
    "        for layer in self.con_layer:\n",
    "            x = Lambda(lambda x: K.permute_dimensions(x, (0,3,1,2)))(x_next)\n",
    "            z_0 = Lambda(lambda x: K.batch_dot(x[0], x[1], axes=(2,3)))([x_0, x])\n",
    "            z_1 = Lambda(lambda x: K.permute_dimensions(x, (0,2,3,1)))(z_0)\n",
    "            \n",
    "            x_next_list = []\n",
    "            pooling_output_list = []\n",
    "            for index in range(layer):\n",
    "                output = Conv2D(3, (int(z_1.shape[1]), int(z_1.shape[2])) )(z_1)\n",
    "                output = Lambda(lambda x: K.squeeze(x, 2))(output)\n",
    "                pooling_output = Lambda(lambda x: K.sum(output, axis = 2))(output)\n",
    "                pooling_output_list.append(pooling_output)\n",
    "                x_next_list.append(output)\n",
    "            x_next = Concatenate(axis = 1)(x_next_list)\n",
    "            x_next = Lambda(lambda x: K.expand_dims(x, axis = 2))(x_next)\n",
    "            \n",
    "            x_pooling = Concatenate(axis = 1)(pooling_output_list)\n",
    "            cin_output.append(x_pooling)\n",
    "        \n",
    "        cin_output =  Concatenate(axis = 1)(cin_output)\n",
    "        cin_output = Dense(1, activation='linear')(cin_output)\n",
    "        '''\n",
    "        \n",
    "        dense_input = Input(shape = (len(self.dense_features), ))\n",
    "        \n",
    "        dnn_input = Concatenate(axis=1)([Flatten()(cat_output), dense_input])\n",
    "        #dnn_input = dense_input \n",
    "        dnn_output = dnn_input \n",
    "        for layer in self.hidden_layer:\n",
    "            dnn_output  = BatchNormalization()(dnn_output)\n",
    "            dnn_output  = Dense(layer, activation='relu')(dnn_output)\n",
    "            dnn_output  = Dropout(0.2)(dnn_output)\n",
    "        dnn_output = Dense(1, activation='linear')(dnn_output)\n",
    "        \n",
    "        #output  = Concatenate(axis=1)([first_order, second_order, dnn_output])\n",
    "        output  = Add()([first_order, cin_output, dnn_output])\n",
    "        output = Dense(1, activation='sigmoid')(output)\n",
    "        model = Model(inputs = cat_input + [dense_input], outputs=output)\n",
    "        print(\"---starting the training---\")\n",
    "        model.compile(\n",
    "            optimizer=\"adam\",\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "        print(model.summary())\n",
    "        model.fit([train[f] for f in self.sparse_features] + [train[self.dense_features]], y_train, epochs = n_epoch, batch_size= n_batch)\n",
    "        self.model = model\n",
    "        \n",
    "    def predict(self, test):\n",
    "        y_pred = self.model.predict([test[f] for f in self.sparse_features] +  [test[self.dense_features]])\n",
    "        return y_pred\n",
    "    \n",
    "    def evaluate(self, test, y_test, metrics):\n",
    "        #loss, accuracy = self.model.evaluate([test[f] for f in self.sparse_features] +  [test[self.dense_features]], y_test)\n",
    "        #print('\\n', 'test accuracy:', accuracy)\n",
    "        y_pred = self.predict(test)\n",
    "        return metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---loading and preprocessing the data---\n"
     ]
    }
   ],
   "source": [
    "print(\"---loading and preprocessing the data---\")\n",
    "data = load_data()\n",
    "data = data.set_index(\"id\")\n",
    "target = data['target']\n",
    "data.drop(['target'], axis=1, inplace=True)\n",
    "#data = preprocess(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse : unique sum  376\n",
      "27 30\n",
      "(595212, 57)\n",
      "(595212, 57)\n"
     ]
    }
   ],
   "source": [
    "from util import *\n",
    "\n",
    "data, sparse_features, dense_features = recognize_feature(data)\n",
    "print(len(dense_features),len(sparse_features))\n",
    "\n",
    "sparse_label_dict = dict()\n",
    "for f in sparse_features:\n",
    "    sparse_label_dict[f] = data[f].max()\n",
    "\n",
    "print(data.shape)\n",
    "#data = one_hot_for_sparse(data, sparse_features)\n",
    "#data = scalar_for_dense(data, dense_features)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ps_ind_01': 7, 'ps_ind_02_cat': 4, 'ps_ind_03': 11, 'ps_ind_04_cat': 2, 'ps_ind_05_cat': 7, 'ps_ind_14': 4, 'ps_ind_15': 13, 'ps_car_01_cat': 12, 'ps_car_02_cat': 2, 'ps_car_03_cat': 2, 'ps_car_04_cat': 9, 'ps_car_05_cat': 2, 'ps_car_06_cat': 17, 'ps_car_07_cat': 2, 'ps_car_08_cat': 1, 'ps_car_09_cat': 5, 'ps_car_10_cat': 2, 'ps_car_11_cat': 103, 'ps_car_11': 4, 'ps_calc_04': 5, 'ps_calc_05': 6, 'ps_calc_06': 10, 'ps_calc_07': 9, 'ps_calc_08': 10, 'ps_calc_09': 7, 'ps_calc_10': 25, 'ps_calc_11': 19, 'ps_calc_12': 10, 'ps_calc_13': 13, 'ps_calc_14': 23}\n"
     ]
    }
   ],
   "source": [
    "print(sparse_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, y_train, y_test = train_test_split(data, target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reset_index().drop(\"id\", axis =1)\n",
    "test = test.reset_index().drop(\"id\", axis =1)\n",
    "y_train = y_train.reset_index().drop(\"id\", axis =1)\n",
    "y_test = y_test.reset_index().drop(\"id\", axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "model = XDeepFM(sparse_features, dense_features, sparse_label_dict, [2048, 100, 50] , [25, 20, 20], 3)\n",
    "model.fit(train, y_train, 100, 1000)\n",
    "model.evaluate(test, y_test, roc_auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "from Keras.XDeepFM import XDeepFM\n",
    "model = XDeepFM(sparse_features, dense_features, sparse_label_dict, [2048, 100, 50] , [25, 20, 20], 3)\n",
    "model.fit(train, y_train, 50, 1000)\n",
    "model.evaluate(test, y_test, roc_auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "from Tensorflow.TFModel import *\n",
    "model =TFModel(sparse_features, dense_features, sparse_label_dict, [2048, 100, 50] , 3)\n",
    "model.fit(train, y_train, 100, 1000)\n",
    "model.evaluate(test, y_test, roc_auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "from Keras.DeepFM import *\n",
    "model = DeepFM(sparse_features, dense_features, sparse_label_dict, [2048, 100, 50] , 3)\n",
    "model.fit(train, y_train, 100, 1000)\n",
    "model.evaluate(test, y_test, roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 3, 30, 30)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "next shape (?, 25, 1, 3)\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 3, 25, 30)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "next shape (?, 20, 1, 3)\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 3, 20, 30)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "(?, 1)\n",
      "next shape (?, 20, 1, 3)\n",
      "epoch 0:\n",
      "the times of training is 0, and the loss is 0.69369173\n",
      "the times of training is 100, and the loss is 0.15586999\n",
      "the times of training is 200, and the loss is 0.15326853\n",
      "the times of training is 300, and the loss is 0.15240566\n",
      "epoch 1:\n",
      "the times of training is 0, and the loss is 0.1588198\n",
      "the times of training is 100, and the loss is 0.15529771\n",
      "the times of training is 200, and the loss is 0.15321171\n",
      "the times of training is 300, and the loss is 0.15088971\n",
      "epoch 2:\n",
      "the times of training is 0, and the loss is 0.15849233\n",
      "the times of training is 100, and the loss is 0.15515704\n",
      "the times of training is 200, and the loss is 0.15283145\n",
      "the times of training is 300, and the loss is 0.1505125\n",
      "epoch 3:\n",
      "the times of training is 0, and the loss is 0.15809059\n",
      "the times of training is 100, and the loss is 0.1547287\n",
      "the times of training is 200, and the loss is 0.15309367\n",
      "the times of training is 300, and the loss is 0.15013175\n",
      "epoch 4:\n",
      "the times of training is 0, and the loss is 0.15716141\n",
      "the times of training is 100, and the loss is 0.15384544\n",
      "the times of training is 200, and the loss is 0.15361466\n",
      "the times of training is 300, and the loss is 0.14993292\n",
      "epoch 5:\n",
      "the times of training is 0, and the loss is 0.15593764\n",
      "the times of training is 100, and the loss is 0.1527143\n",
      "the times of training is 200, and the loss is 0.153855\n",
      "the times of training is 300, and the loss is 0.14971505\n",
      "epoch 6:\n",
      "the times of training is 0, and the loss is 0.15462375\n",
      "the times of training is 100, and the loss is 0.15169409\n",
      "the times of training is 200, and the loss is 0.15400921\n",
      "the times of training is 300, and the loss is 0.14952476\n",
      "epoch 7:\n",
      "the times of training is 0, and the loss is 0.15311268\n",
      "the times of training is 100, and the loss is 0.15078455\n",
      "the times of training is 200, and the loss is 0.1535606\n",
      "the times of training is 300, and the loss is 0.14876945\n",
      "epoch 8:\n",
      "the times of training is 0, and the loss is 0.1515347\n",
      "the times of training is 100, and the loss is 0.14963345\n",
      "the times of training is 200, and the loss is 0.1528256\n",
      "the times of training is 300, and the loss is 0.14758219\n",
      "epoch 9:\n",
      "the times of training is 0, and the loss is 0.14999326\n",
      "the times of training is 100, and the loss is 0.14846839\n",
      "the times of training is 200, and the loss is 0.15123557\n",
      "the times of training is 300, and the loss is 0.14638115\n",
      "epoch 10:\n",
      "the times of training is 0, and the loss is 0.1488814\n",
      "the times of training is 100, and the loss is 0.14704457\n",
      "the times of training is 200, and the loss is 0.15061449\n",
      "the times of training is 300, and the loss is 0.14407559\n",
      "epoch 11:\n",
      "the times of training is 0, and the loss is 0.14696954\n",
      "the times of training is 100, and the loss is 0.14427918\n",
      "the times of training is 200, and the loss is 0.15137896\n",
      "the times of training is 300, and the loss is 0.1374535\n",
      "epoch 12:\n",
      "the times of training is 0, and the loss is 0.14226812\n",
      "the times of training is 100, and the loss is 0.14062232\n",
      "the times of training is 200, and the loss is 0.1443804\n",
      "the times of training is 300, and the loss is 0.12590061\n",
      "epoch 13:\n",
      "the times of training is 0, and the loss is 0.13889956\n",
      "the times of training is 100, and the loss is 0.13622719\n",
      "the times of training is 200, and the loss is 0.13286771\n",
      "the times of training is 300, and the loss is 0.113713294\n",
      "epoch 14:\n",
      "the times of training is 0, and the loss is 0.13659082\n",
      "the times of training is 100, and the loss is 0.13138942\n",
      "the times of training is 200, and the loss is 0.12031327\n",
      "the times of training is 300, and the loss is 0.09162241\n",
      "epoch 15:\n",
      "the times of training is 0, and the loss is 0.12802231\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/yongsaima/DeepCTR_tensorflow_keras_pytorch/Tensorflow/TFModel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train, y_train, epoch, batch_size)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'the times of training is %d, and the loss is %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yongsaima/DeepCTR_tensorflow_keras_pytorch/Tensorflow/XDeepFM.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sess, train, y_train, drop_out)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrop_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from Tensorflow.XDeepFM import XDeepFM\n",
    "model = XDeepFM(sparse_features, dense_features, sparse_label_dict, [2048, 100, 50] , 3)\n",
    "model.fit(train, y_train, 50, 1000)\n",
    "metric = model.evaluate(test, y_test, roc_auc_score)\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8,)\n",
      "(1, 2, 8)\n",
      "(1, 2)\n",
      "[[[1. 2. 3. 4. 1. 2. 3. 4.]\n",
      "  [1. 2. 3. 4. 1. 2. 3. 4.]]]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[[20. 20.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "img1 = tf.constant(value=[[[[1],[2],[3],[4]],[[1],[2],[3],[4]],[[1],[2],[3],[4]],[[1],[2],[3],[4]]]],dtype=tf.float32)\n",
    "img2 = tf.constant(value=[[[[1],[1],[1],[1]],[[1],[1],[1],[1]],[[1],[1],[1],[1]],[[1],[1],[1],[1]]]],dtype=tf.float32)\n",
    "img1 = tf.reshape(img1, [1, 2, 8])\n",
    "filter = tf.Variable(tf.ones([8]))\n",
    "print(filter.shape)\n",
    "print(img1.shape)\n",
    "#res = tf.multiply(filter, img1)\n",
    "res = tf.tensordot(img1, filter, axes = [[2], [0]])\n",
    "print(res.shape)\n",
    "with tf.Session() as sess:\n",
    "    # 初始化\n",
    "    tf.global_variables_initializer().run()\n",
    "    # 输出卷积值\n",
    "    print(sess.run(img1))\n",
    "    print(sess.run(filter))\n",
    "    print(sess.run(res))\n",
    "\n",
    "#out_img = tf.nn.depthwise_conv2d(input=img, filter=filter, strides=[1,1,1,1], rate=[1,1], padding='VALID')\n",
    "#print(out_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape_66:0\", shape=(1, 4, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "img1 = tf.constant(value=[[[[1],[2],[3],[4]],[[1],[2],[3],[4]],[[1],[2],[3],[4]],[[1],[2],[3],[4]]]],dtype=tf.float32)\n",
    "img2 = tf.constant(value=[[[[1],[1],[1],[1]],[[1],[1],[1],[1]],[[1],[1],[1],[1]],[[1],[1],[1],[1]]]],dtype=tf.float32)\n",
    "img1 = tf.reshape(img1, [-1, 4, 4])\n",
    "print(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 1.  2.]\n",
      "   [ 3.  4.]\n",
      "   [ 5.  6.]]\n",
      "\n",
      "  [[ 7.  8.]\n",
      "   [ 9. 10.]\n",
      "   [11. 12.]]]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape must be rank 4 but is rank 5 for 'conv1d/Conv2D' (op: 'Conv2D') with input shapes: [1,1,2,3,2], [1,6,2,1].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    685\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    687\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape must be rank 4 but is rank 5 for 'conv1d/Conv2D' (op: 'Conv2D') with input shapes: [1,1,2,3,2], [1,6,2,1].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1b5ee1f9efb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#print(kernel)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# 进行conv1d卷积\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mconv1d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'VALID'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m#conv2d = tf.layers.separable_conv2d(a, 1, (2,3))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    495\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 497\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    499\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    495\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 497\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    499\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconv1d\u001b[0;34m(value, filters, stride, padding, use_cudnn_on_gpu, data_format, name)\u001b[0m\n\u001b[1;32m   2418\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m         \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m         data_format=data_format)\n\u001b[0m\u001b[1;32m   2421\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mspatial_start_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;34m\"Conv2D\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m         data_format=data_format, dilations=dilations, name=name)\n\u001b[0m\u001b[1;32m    632\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3271\u001b[0m         op_def=op_def)\n\u001b[1;32m   3272\u001b[0m     self._create_op_helper(ret, compute_shapes=compute_shapes,\n\u001b[0;32m-> 3273\u001b[0;31m                            compute_device=compute_device)\n\u001b[0m\u001b[1;32m   3274\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_helper\u001b[0;34m(self, op, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3311\u001b[0m     \u001b[0;31m# compute_shapes argument.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3312\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3313\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3314\u001b[0m     \u001b[0;31m# TODO(b/XXXX): move to Operation.__init__ once _USE_C_API flag is removed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3315\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2499\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_set_shapes_for_outputs_c_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2500\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_set_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_set_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2472\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2474\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2475\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2476\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2403\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2404\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2406\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    689\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape must be rank 4 but is rank 5 for 'conv1d/Conv2D' (op: 'Conv2D') with input shapes: [1,1,2,3,2], [1,6,2,1]."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 定义一个矩阵a，表示需要被卷积的矩阵。 2 *3 ,然后两维度\n",
    "a = np.array(np.arange(1, 13).reshape([1, 2, 3 , 2]), dtype=np.float32)\n",
    "print(a)\n",
    "# 卷积核，此处卷积filter的数目为1个（表示h_k+1）， 卷积的宽度是2*3 = 6， 卷积的深度input =2， output channel = 1\n",
    "# 实际上权重数目是2 * 3 * 2 ，但是一个卷积核又有output channel 个核。\n",
    "kernel = np.array(np.ones(12), dtype=np.float32).reshape([6, 2, 1])\n",
    "#print(kernel)\n",
    "# 进行conv1d卷积\n",
    "conv1d = tf.nn.conv1d(a, kernel, 1, 'VALID')\n",
    "#conv2d = tf.layers.separable_conv2d(a, 1, (2,3))\n",
    "with tf.Session() as sess:\n",
    "    # 初始化\n",
    "    tf.global_variables_initializer().run()\n",
    "    # 输出卷积值\n",
    "    print(sess.run(conv1d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.python.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(DepthwiseConv2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
